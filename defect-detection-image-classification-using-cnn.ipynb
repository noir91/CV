{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":792851,"sourceType":"datasetVersion","datasetId":414522}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset, Subset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nimport torch\n\n# reproducibility\nrandom.seed(42)\ntorch.manual_seed(42)\n\n# Data Transformation pipeline\ntransforms_ = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor()\n])\n# define data path\ndata_path = r'/kaggle/input/surface-crack-detection/'\ndataset = ImageFolder(data_path, transform = transforms_) # add transformations with (x,z) where z is transformation\n\n#classes = data.classes\n#extensions = data.extensions\n#images = data.samples\n\n\n# Split size\ntotal_length = len(dataset)\nindices = list(range(total_length))\nrandom.shuffle(indices)\n\ntrain_size = int(0.70 * total_length)\nval_size = int(0.15* total_length)\n\n# Indexes \ntrain_idx = indices[:train_size]\nval_idx = indices[train_size : train_size + val_size]\ntest_idx = indices[train_size + val_size :]\n\n# Subsets\ntrain_subset = Subset(dataset, train_idx)\nval_subset = Subset(dataset, val_idx)\ntest_subset = Subset(dataset, test_idx)\n\n# Dataloader for shuffle & batch_size\ntestset = DataLoader(test_subset, shuffle=False, batch_size=32, num_workers=4, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T05:27:21.821585Z","iopub.execute_input":"2025-06-12T05:27:21.822226Z","iopub.status.idle":"2025-06-12T05:28:03.667394Z","shell.execute_reply.started":"2025-06-12T05:27:21.822197Z","shell.execute_reply":"2025-06-12T05:28:03.666780Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Model Class","metadata":{}},{"cell_type":"code","source":"!pip install torch.nn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch.nn as nn\nimport torch\nimport torchvision\nimport numpy as np\nimport torch.optim as optim\n\nclass CNN(nn.Module):\n    def __init__(self, trial = None, out_1 = None, out_2 = None, layers = None):\n        super(CNN, self).__init__()\n        # search space\n        if trial is not None:\n            out_1 = trial.suggest_int('out_1',16, 64, step = 8)\n            out_2 = trial.suggest_int('out_2', 64, 128, step = 8)\n            layers = trial.suggest_int('layers', 64, 128, step =8)\n\n        # params\n        self.out_1 = out_1\n        self.out_2 = out_2\n        self.layers = layers\n                                #dropout = trial.suggest_float('dropout', 0.2, 0.5)\n        # convo layer - 1\n        #out_1 = trial.suggest_int('out_1', 16, 64, step = 8)\n        self.conv1 = nn.Conv2d(3, out_1, kernel_size = 3, padding = 1)\n        self.bn1 = nn.BatchNorm2d(out_1)\n        self.relu1 = nn.ReLU()\n        self.max2d_1 = nn.MaxPool2d(kernel_size = 2)\n        \n        # convo layer - 2\n        #out_2 = trial.suggest_int('out_2', 64, 128, step = 8)\n        self.conv2 = nn.Conv2d(out_1, out_2, kernel_size = 3, padding = 1)\n        self.bn2 = nn.BatchNorm2d(out_2)\n        self.relu2 = nn.ReLU()\n        self.max2d_2 = nn.MaxPool2d(kernel_size = 2)\n\n        # input dimensions\n        dummy = torch.randn(1,3,224, 224)\n        with torch.no_grad():\n            x = self.relu1(self.bn1(self.conv1(dummy)))\n            x = self.max2d_1(x)\n            x = self.relu2(self.bn2(self.conv2(x)))\n            x = self.max2d_2(x)\n            \n            n_features = x.view(1, -1).shape[1]\n\n        # Dense layer\n        self.fc1 = nn.Linear(n_features, layers)\n        self.relu3 = nn.ReLU()\n        \n        self.fc2 = nn.Linear(layers, 1)\n\n    def forward(self, x):\n        x = self.relu1(self.bn1(self.conv1(x)))\n        x = self.max2d_1(x)\n\n        x = self.relu2(self.bn2(self.conv2(x)))\n        x = self.max2d_2(x)\n\n        x = x.view(x.size(0), -1)\n\n        x = self.relu3(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T05:24:30.513505Z","iopub.execute_input":"2025-06-12T05:24:30.514077Z","iopub.status.idle":"2025-06-12T05:24:30.522912Z","shell.execute_reply.started":"2025-06-12T05:24:30.514056Z","shell.execute_reply":"2025-06-12T05:24:30.522138Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\ndevice = xm.xla_device()\n\nprint(xm.get_xla_supported_devices())\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install optuna","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport os\nimport optuna\n\n# Example CNN class placeholder\ndef train_one_epoch(model, trainset, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for imgs, labels in trainset:\n        imgs, labels = imgs.to(device), labels.to(device)\n        labels = labels.float().unsqueeze(1)\n\n        output = model(imgs)\n        loss = criterion(output, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * imgs.size(0)\n        preds = (torch.sigmoid(output) > 0.5).long()\n        correct += (preds == labels.long()).sum().item()\n        total += labels.size(0)\n    if total == 0:\n        return 0.0,0.0\n    return running_loss / total, correct / total\n\n\ndef validate(model, valset, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for imgs, labels in valset:\n            imgs, labels = imgs.to(device), labels.to(device)\n            labels = labels.float().unsqueeze(1)\n\n            output = model(imgs)\n            loss = criterion(output, labels)\n\n            running_loss += loss.item() * imgs.size(0)\n            preds = (torch.sigmoid(output) > 0.5).long()\n            correct += (preds == labels.long()).sum().item()\n            total += labels.size(0)\n            \n    return running_loss / total, correct / total\n\n\ndef objective(trial, trainset, valset):\n    criterion = nn.BCEWithLogitsLoss()\n    epochs = 10\n    patience = 3\n    early_stop_counter = 0\n    best_val_loss = float('inf')\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Build model from trial\n    model = CNN(trial).to(device)\n\n    # Hyperparameter suggestions\n    batch_size = trial.suggest_categorical('batch_size', [16, 32])\n    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n    optimizer_name = trial.suggest_categorical('optimizers', [\"Adam\", \"SGD\", \"Adagrad\"])\n    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n\n    if optimizer_name == \"SGD\":\n        momentum = trial.suggest_float('momentum', 0.5, 0.99, log=True)\n        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n    else:\n        optimizer_class = getattr(optim, optimizer_name)\n        optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n    # data\n    train_loader = DataLoader(trainset, shuffle=True, batch_size=batch_size, num_workers=8, pin_memory=True)\n    val_loader = DataLoader(valset, shuffle=False, batch_size=batch_size, num_workers=8, pin_memory=True)\n    \n    # Training loop\n    best_state_dict = None\n    for epoch in range(epochs):\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n    \n        print(f\"Epoch [{epoch + 1}/{epochs}] | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n    \n        trial.report(val_loss, step=epoch)\n    \n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n    \n        if val_loss < best_val_loss - 1e-4:\n            best_val_loss = val_loss\n            best_train_loss = train_loss\n            best_train_acc = train_acc\n            best_val_acc = val_acc\n            early_stop_counter = 0\n            best_state_dict = model.state_dict()  # Keep best model in memory\n        else:\n            early_stop_counter += 1\n            if early_stop_counter >= patience:\n                print(\"Early stopping triggered.\")\n                break\n\n    # Save best model once at the end\n    if best_state_dict:\n        os.makedirs(\"models\", exist_ok=True)\n        model_path = f\"models/best_model_trial_{trial.number}.pt\"\n        torch.save(best_state_dict, model_path)\n        trial.set_user_attr('model_path', model_path)\n    \n    trial.set_user_attr(\"train_loss\", best_train_loss)\n    trial.set_user_attr(\"train_acc\", best_train_acc)\n    trial.set_user_attr(\"val_loss\", best_val_loss)\n    trial.set_user_attr(\"val_acc\", best_val_acc)\n\n    return best_val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T04:24:27.115572Z","iopub.execute_input":"2025-06-12T04:24:27.116010Z","iopub.status.idle":"2025-06-12T04:24:27.131877Z","shell.execute_reply.started":"2025-06-12T04:24:27.115981Z","shell.execute_reply":"2025-06-12T04:24:27.130900Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Training and Validation","metadata":{}},{"cell_type":"code","source":"import optuna\n\ndef objective_wrapper(trainset, valset):\n    def wrapped(trial):\n        return objective(trial, trainset, valset)\n    return wrapped\n\nstudy = optuna.create_study(direction = 'minimize', pruner = optuna.pruners.MedianPruner(n_warmup_steps = 3))\nstudy.optimize(objective_wrapper(train_subset, val_subset), n_trials = 10, show_progress_bar = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T04:24:47.661537Z","iopub.execute_input":"2025-06-12T04:24:47.661859Z","iopub.status.idle":"2025-06-12T05:14:52.066631Z","shell.execute_reply.started":"2025-06-12T04:24:47.661839Z","shell.execute_reply":"2025-06-12T05:14:52.065523Z"}},"outputs":[{"name":"stderr","text":"[I 2025-06-12 04:24:47,663] A new study created in memory with name: no-name-308bc5fb-4680-4c4e-bdcb-38ae67968e6c\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c857c402a140c4aa387214af1a23c7"}},"metadata":{}},{"name":"stdout","text":"Epoch [1/10] | Train Loss: 0.4184 Acc: 0.9365 | Val Loss: 0.0818 Acc: 0.9670\nEpoch [2/10] | Train Loss: 0.1187 Acc: 0.9615 | Val Loss: 0.0686 Acc: 0.9823\nEpoch [3/10] | Train Loss: 0.0975 Acc: 0.9759 | Val Loss: 0.0291 Acc: 0.9925\nEpoch [4/10] | Train Loss: 0.0500 Acc: 0.9875 | Val Loss: 0.0283 Acc: 0.9915\nEpoch [5/10] | Train Loss: 0.0395 Acc: 0.9899 | Val Loss: 0.0339 Acc: 0.9888\nEpoch [6/10] | Train Loss: 0.0330 Acc: 0.9915 | Val Loss: 0.0404 Acc: 0.9898\nEpoch [7/10] | Train Loss: 0.0267 Acc: 0.9926 | Val Loss: 0.0346 Acc: 0.9917\nEarly stopping triggered.\n[I 2025-06-12 04:34:29,754] Trial 0 finished with value: 0.028286033366496363 and parameters: {'out_1': 64, 'out_2': 104, 'layers': 120, 'batch_size': 16, 'lr': 0.0022682026914930455, 'optimizers': 'Adam', 'weight_decay': 0.0002809753042472424}. Best is trial 0 with value: 0.028286033366496363.\nEpoch [1/10] | Train Loss: 1.8994 Acc: 0.9679 | Val Loss: 0.4472 Acc: 0.9800\nEpoch [2/10] | Train Loss: 0.2296 Acc: 0.9842 | Val Loss: 0.3624 Acc: 0.9758\nEpoch [3/10] | Train Loss: 0.1087 Acc: 0.9899 | Val Loss: 0.0998 Acc: 0.9918\nEpoch [4/10] | Train Loss: 0.0779 Acc: 0.9919 | Val Loss: 0.1969 Acc: 0.9855\nEpoch [5/10] | Train Loss: 0.0611 Acc: 0.9926 | Val Loss: 0.1283 Acc: 0.9827\nEpoch [6/10] | Train Loss: 0.0403 Acc: 0.9946 | Val Loss: 0.0829 Acc: 0.9925\nEpoch [7/10] | Train Loss: 0.0340 Acc: 0.9955 | Val Loss: 0.0880 Acc: 0.9925\nEpoch [8/10] | Train Loss: 0.0254 Acc: 0.9962 | Val Loss: 0.0902 Acc: 0.9913\nEpoch [9/10] | Train Loss: 0.0158 Acc: 0.9969 | Val Loss: 0.0774 Acc: 0.9908\nEpoch [10/10] | Train Loss: 0.0147 Acc: 0.9974 | Val Loss: 0.0544 Acc: 0.9937\n[I 2025-06-12 04:45:33,180] Trial 1 finished with value: 0.05441191516493418 and parameters: {'out_1': 48, 'out_2': 80, 'layers': 80, 'batch_size': 16, 'lr': 0.00856277891056631, 'optimizers': 'Adagrad', 'weight_decay': 1.1640391185797078e-05}. Best is trial 0 with value: 0.028286033366496363.\nEpoch [1/10] | Train Loss: 0.5921 Acc: 0.9637 | Val Loss: 0.1358 Acc: 0.9575\nEpoch [2/10] | Train Loss: 0.0743 Acc: 0.9786 | Val Loss: 0.0767 Acc: 0.9648\nEpoch [3/10] | Train Loss: 0.0600 Acc: 0.9805 | Val Loss: 0.0410 Acc: 0.9753\nEpoch [4/10] | Train Loss: 0.0445 Acc: 0.9884 | Val Loss: 0.0262 Acc: 0.9935\nEpoch [5/10] | Train Loss: 0.0354 Acc: 0.9915 | Val Loss: 0.0219 Acc: 0.9937\nEpoch [6/10] | Train Loss: 0.0216 Acc: 0.9950 | Val Loss: 0.0305 Acc: 0.9928\nEpoch [7/10] | Train Loss: 0.0144 Acc: 0.9967 | Val Loss: 0.0370 Acc: 0.9957\nEpoch [8/10] | Train Loss: 0.0174 Acc: 0.9960 | Val Loss: 0.0180 Acc: 0.9952\nEpoch [9/10] | Train Loss: 0.0158 Acc: 0.9968 | Val Loss: 0.0193 Acc: 0.9950\nEpoch [10/10] | Train Loss: 0.0245 Acc: 0.9963 | Val Loss: 0.0277 Acc: 0.9912\n[I 2025-06-12 04:55:52,616] Trial 2 finished with value: 0.01804935360905559 and parameters: {'out_1': 40, 'out_2': 80, 'layers': 88, 'batch_size': 16, 'lr': 0.0032909351941441934, 'optimizers': 'Adam', 'weight_decay': 2.168825586729465e-06}. Best is trial 2 with value: 0.01804935360905559.\nEpoch [1/10] | Train Loss: 0.1354 Acc: 0.9553 | Val Loss: 0.0947 Acc: 0.9705\nEpoch [2/10] | Train Loss: 0.0809 Acc: 0.9753 | Val Loss: 0.0761 Acc: 0.9747\nEpoch [3/10] | Train Loss: 0.0672 Acc: 0.9805 | Val Loss: 0.0705 Acc: 0.9767\nEpoch [4/10] | Train Loss: 0.0605 Acc: 0.9813 | Val Loss: 0.0639 Acc: 0.9777\nEpoch [5/10] | Train Loss: 0.0553 Acc: 0.9836 | Val Loss: 0.0604 Acc: 0.9815\nEpoch [6/10] | Train Loss: 0.0519 Acc: 0.9843 | Val Loss: 0.0558 Acc: 0.9830\nEpoch [7/10] | Train Loss: 0.0473 Acc: 0.9862 | Val Loss: 0.0525 Acc: 0.9825\nEpoch [8/10] | Train Loss: 0.0451 Acc: 0.9869 | Val Loss: 0.0502 Acc: 0.9838\nEpoch [9/10] | Train Loss: 0.0431 Acc: 0.9880 | Val Loss: 0.0484 Acc: 0.9842\nEpoch [10/10] | Train Loss: 0.0406 Acc: 0.9888 | Val Loss: 0.0466 Acc: 0.9848\n[I 2025-06-12 05:06:51,524] Trial 3 finished with value: 0.046619024573514856 and parameters: {'out_1': 40, 'out_2': 104, 'layers': 80, 'batch_size': 16, 'lr': 3.3486622397241524e-05, 'optimizers': 'Adagrad', 'weight_decay': 9.769949566733228e-06}. Best is trial 2 with value: 0.01804935360905559.\nEpoch [1/10] | Train Loss: 0.4292 Acc: 0.9320 | Val Loss: 0.1031 Acc: 0.9592\nEpoch [2/10] | Train Loss: 0.1034 Acc: 0.9714 | Val Loss: 0.0595 Acc: 0.9798\nEpoch [3/10] | Train Loss: 0.0782 Acc: 0.9770 | Val Loss: 0.0574 Acc: 0.9738\nEpoch [4/10] | Train Loss: 0.0622 Acc: 0.9809 | Val Loss: 0.0846 Acc: 0.9767\nEpoch [5/10] | Train Loss: 0.0531 Acc: 0.9836 | Val Loss: 0.0384 Acc: 0.9852\n[W 2025-06-12 05:14:52,027] Trial 4 failed with parameters: {'out_1': 56, 'out_2': 120, 'layers': 120, 'batch_size': 16, 'lr': 0.0017327246908921735, 'optimizers': 'Adam', 'weight_decay': 0.0038288155112372294} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/59236731.py\", line 5, in wrapped\n    return objective(trial, trainset, valset)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3140280086.py\", line 86, in objective\n    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3140280086.py\", line 25, in train_one_epoch\n    running_loss += loss.item() * imgs.size(0)\n                    ^^^^^^^^^^^\nKeyboardInterrupt\n[W 2025-06-12 05:14:52,030] Trial 4 failed with value None.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/59236731.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/59236731.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobjective_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3140280086.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, trainset, valset)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mbest_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3140280086.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, trainset, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":16},{"cell_type":"markdown","source":"# Loading Saved Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import classification_report\n\n# Load the saved model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CNN(                                   # Recreate your model architecture\n    trial=None,\n    out_1=best_params['out_1'],\n    out_2=best_params['out_2'],\n    layers=best_params['layers']\n)\nmodel.load_state_dict(torch.load(\"models/best_model_trial_2.pt\"))\nmodel.eval()\nmodel.to(device)\n\n# Evaluate on test set\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in testset:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)\n        probs = torch.sigmoid(outputs)  # If you're using BCEWithLogitsLoss\n\n        preds = (probs > 0.5).long()\n\n        all_preds.append(preds.cpu())\n        all_labels.append(labels.cpu())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T05:28:03.668788Z","iopub.execute_input":"2025-06-12T05:28:03.669477Z","iopub.status.idle":"2025-06-12T05:28:11.512671Z","shell.execute_reply.started":"2025-06-12T05:28:03.669452Z","shell.execute_reply":"2025-06-12T05:28:11.511660Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"# Test Scores","metadata":{}},{"cell_type":"code","source":"# Stack all predictions and labels\nall_preds = torch.cat(all_preds)\nall_labels = torch.cat(all_labels)\n\n# Classification report\nprint(classification_report(all_labels.numpy(), all_preds.numpy()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T05:28:11.513848Z","iopub.execute_input":"2025-06-12T05:28:11.514085Z","iopub.status.idle":"2025-06-12T05:28:11.529212Z","shell.execute_reply.started":"2025-06-12T05:28:11.514061Z","shell.execute_reply":"2025-06-12T05:28:11.528584Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99      2977\n           1       0.99      1.00      0.99      3023\n\n    accuracy                           0.99      6000\n   macro avg       0.99      0.99      0.99      6000\nweighted avg       0.99      0.99      0.99      6000\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Saving samples for test - Streamlit.\n","metadata":{}},{"cell_type":"code","source":"X_test = []\ny_test = []\n\nfor i in range(32):\n    features, label = test_subset[i]  # testset = Dataset, not DataLoader\n    X_test.append(features.numpy())  # No squeeze needed\n    y_test.append(label)  # If label is scalar\n\nnp.savez(\"test_samples.npz\", X=X_test, y=y_test, allow_pickle = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T05:45:27.469315Z","iopub.execute_input":"2025-06-12T05:45:27.470152Z","iopub.status.idle":"2025-06-12T05:45:27.612294Z","shell.execute_reply.started":"2025-06-12T05:45:27.470127Z","shell.execute_reply":"2025-06-12T05:45:27.611570Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(f\"features.shape: {features.shape}, labels.shape: {labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T05:44:50.420823Z","iopub.execute_input":"2025-06-12T05:44:50.421459Z","iopub.status.idle":"2025-06-12T05:44:50.425234Z","shell.execute_reply.started":"2025-06-12T05:44:50.421436Z","shell.execute_reply":"2025-06-12T05:44:50.424428Z"}},"outputs":[{"name":"stdout","text":"features.shape: torch.Size([3, 224, 224]), labels.shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":39}]}